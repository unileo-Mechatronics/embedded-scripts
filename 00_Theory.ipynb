{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12839938",
      "metadata": {
        "id": "12839938"
      },
      "source": [
        "# üìò Theoretical Notebook ‚Äì Neural Network Training\n",
        "General guide about datasets, models, training loop, backward pass in PyTorch and TensorFlow/Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "159bf1d1",
      "metadata": {
        "id": "159bf1d1"
      },
      "source": [
        "## üìä Training Workflow Flowchart\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "    A[1. Define Problem] --> B[2. Load Dataset]\n",
        "    B --> C[3. Preprocess Data (normalize, split train/val/test)]\n",
        "    C --> D[4. Create Batches / DataLoader]\n",
        "    D --> E[5. Define Model Architecture]\n",
        "    E --> F[6. Choose Loss, Optimizer, Metrics]\n",
        "    F --> G[7. Training Loop\\n(epochs x batches)]\n",
        "    G --> H[8. Evaluate on Validation/Test]\n",
        "    H --> I[9. Save Model / Deploy]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6edd5dd",
      "metadata": {
        "id": "e6edd5dd"
      },
      "source": [
        "## üìÅ Dataset and Preprocessing\n",
        "\n",
        "Typical steps:\n",
        "- Load dataset\n",
        "- Normalize data\n",
        "- Split into train/validation/test\n",
        "- Create mini‚Äëbatches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c56703",
      "metadata": {
        "id": "a3c56703"
      },
      "outputs": [],
      "source": [
        "# PyTorch: dataset + DataLoader example\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc5863ca",
      "metadata": {
        "id": "fc5863ca"
      },
      "outputs": [],
      "source": [
        "# TensorFlow: dataset + tf.data example\n",
        "import tensorflow as tf\n",
        "\n",
        "(train_images, train_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.astype('float32')/255.0\n",
        "\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "    .shuffle(10000)\n",
        "    .batch(64)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08285aa1",
      "metadata": {
        "id": "08285aa1"
      },
      "source": [
        "## üõ† Model Definition\n",
        "\n",
        "Models can be defined as:\n",
        "- A sequence of layers (`Sequential`)\n",
        "- A custom class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d106d21",
      "metadata": {
        "id": "7d106d21"
      },
      "outputs": [],
      "source": [
        "# PyTorch: simple fully‚Äëconnected model\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de5d0ac",
      "metadata": {
        "id": "2de5d0ac"
      },
      "outputs": [],
      "source": [
        "# Keras: simple Sequential model\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(10, activation='softmax'),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf7353fa",
      "metadata": {
        "id": "cf7353fa"
      },
      "source": [
        "## üîÑ Forward Pass & Loss Function\n",
        "\n",
        "- **Forward pass:** input flows through the layers producing an output.\n",
        "- **Loss function:** measures the error between prediction and target.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "180193e9",
      "metadata": {
        "id": "180193e9"
      },
      "source": [
        "## üîô Backward Pass & Weight Update\n",
        "\n",
        "1. Forward pass ‚Üí prediction\n",
        "2. Compute loss\n",
        "3. Backward pass ‚Üí gradients\n",
        "4. Optimizer updates weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa80bdf5",
      "metadata": {
        "id": "fa80bdf5"
      },
      "outputs": [],
      "source": [
        "# PyTorch: single training step\n",
        "optimizer.zero_grad()\n",
        "outputs = model(x)\n",
        "loss = criterion(outputs, y)\n",
        "loss.backward()\n",
        "optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5a7d7c",
      "metadata": {
        "id": "1d5a7d7c"
      },
      "outputs": [],
      "source": [
        "# TensorFlow: single training step\n",
        "with tf.GradientTape() as tape:\n",
        "    preds = model(x, training=True)\n",
        "    loss = loss_fn(y, preds)\n",
        "grads = tape.gradient(loss, model.trainable_variables)\n",
        "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33667c3e",
      "metadata": {
        "id": "33667c3e"
      },
      "source": [
        "## üîÅ Full Training Loop (concept)\n",
        "\n",
        "```\n",
        "for each epoch:\n",
        "    for each batch:\n",
        "        forward\n",
        "        compute loss\n",
        "        backward\n",
        "        optimizer step\n",
        "    evaluate\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1168f49e",
      "metadata": {
        "id": "1168f49e"
      },
      "outputs": [],
      "source": [
        "# PyTorch: full training loop (schematic)\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25b4234a",
      "metadata": {
        "id": "25b4234a"
      },
      "outputs": [],
      "source": [
        "# TensorFlow: full training loop (schematic)\n",
        "for epoch in range(5):\n",
        "    for x_batch, y_batch in train_ds:\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch, training=True)\n",
        "            loss_value = loss_fn(y_batch, logits)\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c06476",
      "metadata": {
        "id": "72c06476"
      },
      "source": [
        "## üìà Evaluation Loop\n",
        "\n",
        "No gradient computation and no weight update.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8554dd69",
      "metadata": {
        "id": "8554dd69"
      },
      "outputs": [],
      "source": [
        "# PyTorch: evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e41ac6e",
      "metadata": {
        "id": "4e41ac6e"
      },
      "outputs": [],
      "source": [
        "# Keras: evaluation\n",
        "model.evaluate(test_images, test_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9363e9c0",
      "metadata": {
        "id": "9363e9c0"
      },
      "source": [
        "## üíæ Saving the Model\n",
        "\n",
        "- PyTorch: `torch.save(model.state_dict(), 'model.pth')`\n",
        "- Keras: `model.save('model.h5')`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85381b14",
      "metadata": {
        "id": "85381b14"
      },
      "source": [
        "## üìù Summary\n",
        "\n",
        "1. Load + preprocess dataset  \n",
        "2. Create batches  \n",
        "3. Define model  \n",
        "4. Choose loss + optimizer  \n",
        "5. Training loop (forward, loss, backward, update)  \n",
        "6. Evaluation loop  \n",
        "7. Save model\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}